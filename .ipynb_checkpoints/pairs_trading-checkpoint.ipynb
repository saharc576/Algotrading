{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Idea\n",
    "\n",
    "<b>We will create a semi-automatic algorithm that will alert to buy or sell in real-time.</br>\n",
    "This will be done in 4 steps: </b></br>\n",
    "1) Find 2 assets that move similarly with eachother over the past X periods of time. </br>\n",
    "2) Calculate the ratio between them.</br>\n",
    "3) Find the correct signal to buy or sell the assets, by their standard deviation from the mean.</br>\n",
    "4) Alert buy / sell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Concepts\n",
    "<b>Let's go over some of the concpets we'll use in this project:</b></br>\n",
    "1) <u>Cointegration:</u> Similar to correlation. Means that the ratio between two series will vary around a mean. </br>  The two series, Y and X follow the follwing: Y = ⍺ X + e where ⍺ is the constant ratio and e is white noise</br>\n",
    "In plain terms, it means that the ratio between the two financial time series will vary around a constant mean </br>\n",
    "</br>\n",
    "2) <u>Stationarity:</u> A stochastic process whose unconditional joint probability distribution does not change when shifted in time. (basically - not time dependant). </br>\n",
    "3) <u>P-value</u>: The probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct. </br> We will use it to test for conitegration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from asyncio import threads\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "import yfinance as yf\n",
    "from yahoo_fin.stock_info import get_data\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data that will be used\n",
    "We will examine ETFs of tech companies.</br>\n",
    "Our assumption is that each of them is stationary, and that they will probably be cointegrated, or at least correlated. </br>\n",
    "We will be looking at the following ETFs: </br>\n",
    "* VGT\n",
    "* XLK\n",
    "* SMH\n",
    "* SOXX\n",
    "* IYW \n",
    "\n",
    "Which are the Top 5 ETFs considering total assets and 5 years look back window profits. ([etfdb](https://etfdb.com/etfdb-category/technology-equities/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_iyw</th>\n",
       "      <th>Close_vgt</th>\n",
       "      <th>Close_xlk</th>\n",
       "      <th>Close_smh</th>\n",
       "      <th>Close_soxx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-30</th>\n",
       "      <td>11.002267</td>\n",
       "      <td>42.118580</td>\n",
       "      <td>16.467777</td>\n",
       "      <td>36.527378</td>\n",
       "      <td>55.197590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-02</th>\n",
       "      <td>10.987015</td>\n",
       "      <td>42.152905</td>\n",
       "      <td>16.467777</td>\n",
       "      <td>36.048595</td>\n",
       "      <td>54.348396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-03</th>\n",
       "      <td>11.030588</td>\n",
       "      <td>41.895462</td>\n",
       "      <td>16.491020</td>\n",
       "      <td>36.361977</td>\n",
       "      <td>54.569202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-04</th>\n",
       "      <td>10.677643</td>\n",
       "      <td>40.633953</td>\n",
       "      <td>16.088051</td>\n",
       "      <td>35.326054</td>\n",
       "      <td>52.921753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-05</th>\n",
       "      <td>10.712504</td>\n",
       "      <td>40.839943</td>\n",
       "      <td>16.111292</td>\n",
       "      <td>35.430519</td>\n",
       "      <td>53.626595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-02</th>\n",
       "      <td>91.500000</td>\n",
       "      <td>373.269989</td>\n",
       "      <td>143.570007</td>\n",
       "      <td>236.539993</td>\n",
       "      <td>414.160004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-03</th>\n",
       "      <td>91.620003</td>\n",
       "      <td>373.510010</td>\n",
       "      <td>143.820007</td>\n",
       "      <td>238.479996</td>\n",
       "      <td>417.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>94.970001</td>\n",
       "      <td>386.459991</td>\n",
       "      <td>148.869995</td>\n",
       "      <td>246.660004</td>\n",
       "      <td>433.790009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-05</th>\n",
       "      <td>90.150002</td>\n",
       "      <td>366.730011</td>\n",
       "      <td>141.710007</td>\n",
       "      <td>235.080002</td>\n",
       "      <td>412.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-06</th>\n",
       "      <td>89.110001</td>\n",
       "      <td>362.750000</td>\n",
       "      <td>140.570007</td>\n",
       "      <td>232.669998</td>\n",
       "      <td>409.100006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_iyw   Close_vgt   Close_xlk   Close_smh  Close_soxx\n",
       "Date                                                                 \n",
       "2004-01-30  11.002267   42.118580   16.467777   36.527378   55.197590\n",
       "2004-02-02  10.987015   42.152905   16.467777   36.048595   54.348396\n",
       "2004-02-03  11.030588   41.895462   16.491020   36.361977   54.569202\n",
       "2004-02-04  10.677643   40.633953   16.088051   35.326054   52.921753\n",
       "2004-02-05  10.712504   40.839943   16.111292   35.430519   53.626595\n",
       "...               ...         ...         ...         ...         ...\n",
       "2022-05-02  91.500000  373.269989  143.570007  236.539993  414.160004\n",
       "2022-05-03  91.620003  373.510010  143.820007  238.479996  417.589996\n",
       "2022-05-04  94.970001  386.459991  148.869995  246.660004  433.790009\n",
       "2022-05-05  90.150002  366.730011  141.710007  235.080002  412.779999\n",
       "2022-05-06  89.110001  362.750000  140.570007  232.669998  409.100006\n",
       "\n",
       "[4600 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgt = yf.Ticker('VGT').history(period='max')\n",
    "xlk = yf.Ticker('XLK').history(period='max')\n",
    "smh = yf.Ticker('SMH').history(period='max')\n",
    "soxx = yf.Ticker('SOXX').history(period='max')\n",
    "iyw = yf.Ticker('IYW').history(period='max')\n",
    "\n",
    "# merge all ETFs data frames to one, by Close tag\n",
    "vgt_xlk = pd.merge(left = vgt[['Close']], right = xlk[['Close']], left_index = True, right_index = True, \n",
    "              suffixes = ('_vgt', '_xlk'))\n",
    "smh_soxx = pd.merge(left = smh[['Close']], right = soxx[['Close']], left_index = True, right_index = True, \n",
    "              suffixes = ('_smh', '_soxx'))\n",
    "combined = pd.merge(left = vgt_xlk, right = smh_soxx, left_index = True, right_index = True)\n",
    "all = pd.merge(left = iyw[['Close']], right = combined, left_index = True, right_index = True)\n",
    "all.rename(columns={'Close': 'Close_iyw'}, inplace=True)\n",
    "\n",
    "all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def stationarity(a, cutoff = 0.05):\n",
    "    a = np.ravel(a)  # flatten the list\n",
    "    result = adfuller(a)\n",
    "    if result[1] < cutoff:\n",
    "        print('The series is stationary')\n",
    "        print('p-value = ', result[1])\n",
    "        return True\n",
    "    print('The series is NOT stationary')\n",
    "    print('p-value = ', result[1])\n",
    "    return False\n",
    "# stationarity(vgt.history(period='max'))\n",
    "# stationarity(Asset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find cointegration\n",
    "We will use the augmented Engle-Granger two-step cointegration test.</br>\n",
    "The null hypothesis is that there is no cointegration between the pairs. </br>\n",
    "Thus, we will be looking for low pvalue. </br>\n",
    "The threshold we are using is 0.05, which was randomly chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# auxiliary function to find all pairs given a list (nC2)\n",
    "def n_choose_2(lst):\n",
    "    pairs_list = []\n",
    "    for i in range(len(lst) - 1):\n",
    "        rest = lst[i+1:]\n",
    "        for j in range(len(rest)):\n",
    "            pairs_list.append([lst[i], rest[j]])\n",
    "    return pairs_list\n",
    "#n_choose_2([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date\n",
       " 2004-01-30     42.118587\n",
       " 2004-02-02     42.152912\n",
       " 2004-02-03     41.895454\n",
       " 2004-02-04     40.633968\n",
       " 2004-02-05     40.839931\n",
       "                  ...    \n",
       " 2022-05-02    373.269989\n",
       " 2022-05-03    373.510010\n",
       " 2022-05-04    386.459991\n",
       " 2022-05-05    366.730011\n",
       " 2022-05-06    362.750000\n",
       " Name: Close, Length: 4600, dtype: float64,\n",
       " Date\n",
       " 1998-12-22     24.593773\n",
       " 1998-12-23     25.181334\n",
       " 1998-12-24     25.085398\n",
       " 1998-12-28     25.157351\n",
       " 1998-12-29     25.229296\n",
       "                  ...    \n",
       " 2022-05-02    143.570007\n",
       " 2022-05-03    143.820007\n",
       " 2022-05-04    148.869995\n",
       " 2022-05-05    141.710007\n",
       " 2022-05-06    140.570007\n",
       " Name: Close, Length: 5882, dtype: float64,\n",
       " Date\n",
       " 2000-06-05     85.910301\n",
       " 2000-06-06     82.373787\n",
       " 2000-06-07     83.733986\n",
       " 2000-06-08     84.114822\n",
       " 2000-06-09     85.855896\n",
       "                  ...    \n",
       " 2022-05-02    236.539993\n",
       " 2022-05-03    238.479996\n",
       " 2022-05-04    246.660004\n",
       " 2022-05-05    235.080002\n",
       " 2022-05-06    232.669998\n",
       " Name: Close, Length: 5517, dtype: float64,\n",
       " Date\n",
       " 2001-07-13     61.689514\n",
       " 2001-07-16     58.114658\n",
       " 2001-07-17     60.500717\n",
       " 2001-07-18     57.995762\n",
       " 2001-07-19     60.458260\n",
       "                  ...    \n",
       " 2022-05-02    414.160004\n",
       " 2022-05-03    417.589996\n",
       " 2022-05-04    433.790009\n",
       " 2022-05-05    412.779999\n",
       " 2022-05-06    409.100006\n",
       " Name: Close, Length: 5238, dtype: float64,\n",
       " Date\n",
       " 2000-05-19    23.910866\n",
       " 2000-05-22    23.093863\n",
       " 2000-05-23    23.611300\n",
       " 2000-05-24    23.366203\n",
       " 2000-05-25    23.039402\n",
       "                 ...    \n",
       " 2022-05-02    91.500000\n",
       " 2022-05-03    91.620003\n",
       " 2022-05-04    94.970001\n",
       " 2022-05-05    90.150002\n",
       " 2022-05-06    89.110001\n",
       " Name: Close, Length: 5527, dtype: float64]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_cointegrated_pairs(etf_price_list):\n",
    "    cointegrated_pairs = []\n",
    "    # filter the ETFs that aren't stationarity\n",
    "    # etf_price_list = list(filter(lambda a: stationarity(a), etf_price_list))\n",
    "    # create pairs\n",
    "    etf_pairs = n_choose_2(etf_price_list)\n",
    "    # for each pair check for cointegration\n",
    "    for pair in etf_pairs:\n",
    "        threshold = 0.05  \n",
    "        coin_result = coint(pair[0], pair[1])\n",
    "        print(result)\n",
    "        if result[1] <= threshold:\n",
    "            cointegrated_pairs.append(pair)\n",
    "    return cointegrated_pairs\n",
    "        \n",
    "etf_price_list = [data_hist[['Close']] for data_hist in data_hist_list] \n",
    "etf_price_list = [data_hist[['Date']]= for data_hist in data_hist_list] \n",
    "\n",
    "etf_price_list = [data_hist.loc[:,'Close'] for data_hist in etf_price_list] \n",
    "etf_price_list\n",
    "# find_cointegrated_pairs(data_hist_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To add, backtesting and correlaiton and more\n",
    "https://medium.datadriveninvestor.com/creating-and-implementing-a-pairs-trading-strategy-from-scratch-658267bab249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}